{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL_MAIN = \"http://api.nytimes.com/svc/\"\n",
    "URL_POPULAR = URL_MAIN + \"mostpopular/v2/\"\n",
    "API_KEY = { \"popular\": \"\",\n",
    "            \"article\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_from_file(kind, period):\n",
    "    filename = \"popular-{0}-{1}.json\".format(kind, period)\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.loads(f.read())\n",
    "\n",
    "def query_site(url, target, offset):\n",
    "    # This will set up the query with the API key and offset\n",
    "    # Web services often use offset paramter to return data in small chunks\n",
    "    # NYTimes returns 20 articles per request, if you want the next 20\n",
    "    # You have to provide the offset parameter\n",
    "    if API_KEY[\"popular\"] == \"\" or API_KEY[\"article\"] == \"\":\n",
    "        print \"You need to register for NYTimes Developer account to run this program.\"\n",
    "        print \"See Intructor notes for information\"\n",
    "        return False\n",
    "    params = {\"api-key\": API_KEY[target], \"offset\": offset}\n",
    "    r = requests.get(url, params = params)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def get_popular(url, kind, days, section=\"all-sections\", offset=0):\n",
    "    # This function will construct the query according to the requirements of the site\n",
    "    # and return the data, or print an error message if called incorrectly\n",
    "    if days not in [1,7,30]:\n",
    "        print \"Time period can be 1,7, 30 days only\"\n",
    "        return False\n",
    "    if kind not in [\"viewed\", \"shared\", \"emailed\"]:\n",
    "        print \"kind can be only one of viewed/shared/emailed\"\n",
    "        return False\n",
    "\n",
    "    url = URL_POPULAR + \"most{0}/{1}/{2}.json\".format(kind, section, days)\n",
    "    data = query_site(url, \"popular\", offset)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_file(kind, period):\n",
    "    # This will process all results, by calling the API repeatedly with supplied offset value,\n",
    "    # combine the data and then write all results in a file.\n",
    "    data = get_popular(URL_POPULAR, \"viewed\", 1)\n",
    "    num_results = data[\"num_results\"]\n",
    "    full_data = []\n",
    "    with codecs.open(\"popular-{0}-{1}-full.json\".format(kind, period), encoding='utf-8', mode='w') as v:\n",
    "        for offset in range(0, num_results, 20):        \n",
    "            data = get_popular(URL_POPULAR, kind, period, offset=offset)\n",
    "            full_data += data[\"results\"]\n",
    "        \n",
    "        v.write(json.dumps(full_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    # YOUR CODE HERE\n",
    "    titles = [ {dict['section'] : dict['title']} for dict in data ]\n",
    "    urls = [meta['url'] for dict in data\n",
    "                    for medium in dict['media']\n",
    "                    for meta in medium['media-metadata'] if meta['format'] == 'Standard Thumbnail' ]\n",
    "    return (titles, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    titles, urls = article_overview(\"viewed\", 1)\n",
    "    assert len(titles) == 20\n",
    "    assert len(urls) == 30\n",
    "    assert titles[2] == {'Opinion': 'Professors, We Need You!'}\n",
    "    assert urls[20] == 'http://graphics8.nytimes.com/images/2014/02/17/sports/ICEDANCE/ICEDANCE-thumbStandard.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'http://graphics8.nytimes.com/images/2014/02/17/sports/ICEDANCE/ICEDANCE-thumbStandard.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
